openapi: 3.0.1
info:
  title: AI Gateway API
  version: '1.0'
servers:
  - url: https://api.us-east-1.langdb.ai
    description: LangDB API Server
paths:
  /v1/chat/completions:
    post:
      operationId: createChatCompletion
      tags:
        - Completions
      summary: Create chat completion
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateChatCompletionRequest'
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CreateChatCompletionResponse'
      x-oaiMeta:
        name: Create chat completion
        group: chat
        returns: |
          Returns a [chat completion](/docs/api-reference/chat/object) object, or a streamed sequence of [chat completion chunk](/docs/api-reference/chat/streaming) objects if the request is streamed.
        path: create
        examples:
          - title: Default
            request:
              curl: |
                curl https://api.staging.langdb.ai/v1/chat/completions \
                  -H "Content-Type: application/json" \
                  -H "Authorization: Bearer $LANGDB_API_KEY" \
                  -d '{
                    "model": "VAR_model_id",
                    "messages": [
                      {
                        "role": "system",
                        "content": "You are a helpful assistant."
                      },
                      {
                        "role": "user",
                        "content": "Hello!"
                      }
                    ]
                  }'
              python: |
                from openai import OpenAI
                client = OpenAI()

                completion = client.chat.completions.create(
                  model="VAR_model_id",
                  messages=[
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": "Hello!"}
                  ]
                )

                print(completion.choices[0].message)
              node.js: |-
                import OpenAI from "openai";

                const openai = new OpenAI();

                async function main() {
                  const completion = await openai.chat.completions.create({
                    messages: [{ role: "system", content: "You are a helpful assistant." }],
                    model: "VAR_model_id",
                  });

                  console.log(completion.choices[0]);
                }

                main();
            response: |
              {
                "id": "chatcmpl-123",
                "object": "chat.completion",
                "created": 1677652288,
                "model": "gpt-4o-mini",
                "system_fingerprint": "fp_44709d6fcb",
                "choices": [{
                  "index": 0,
                  "message": {
                    "role": "assistant",
                    "content": "\n\nHello there, how may I assist you today?",
                  },
                  "logprobs": null,
                  "finish_reason": "stop"
                }],
                "usage": {
                  "prompt_tokens": 9,
                  "completion_tokens": 12,
                  "total_tokens": 21,
                  "completion_tokens_details": {
                    "reasoning_tokens": 0,
                    "accepted_prediction_tokens": 0,
                    "rejected_prediction_tokens": 0
                  }
                }
              }
      security:
        - BearerAuth: []
          ProjectIdAuth: []
  /v1/embeddings:
    post:
      operationId: generateEmbeddings
      tags:
        - Completions
      summary: Create embeddings
      description: |
        Creates an embedding vector representing the input text or token arrays.

      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/EmbeddingsRequest"
            examples:
              singleInputFloat:
                summary: A single text input, returning float array
                value:
                  input: "The food was delicious and the waiter was kind."
                  model: "text-embedding-ada-002"
                  encoding_format: "float"
                  dimensions: 1536
              multipleInputsBase64:
                summary: Multiple text strings, returning base64-encoded vectors
                value:
                  input:
                    - "First text to embed"
                    - "Second text to embed"
                  model: "text-embedding-3-small"
                  encoding_format: "base64"
      responses:
        '200':
          description: Successful response with embeddings
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/EmbeddingsResponse"
      security:
        - BearerAuth: []
          ProjectIdAuth: []
          
  /threads:
    post:
      operationId: listThreads
      tags:
        - Threads
      summary: Retrieve a list of threads
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ThreadsRequest'
      responses:
        '200':
          description: A list of threads with pagination info
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ThreadsResponse'
                
        
      security:
        - BearerAuth: []
          ProjectIdAuth: []
          
  /threads/{thread_id}/messages:
    get:
      operationId: listThreadMessages
      tags:
        - Threads
      summary: Retrieve messages for a specific thread
      parameters:
        - name: thread_id
          in: path
          required: true
          schema:
            type: string
            format: uuid
          description: The ID of the thread to retrieve messages from
      responses:
        '200':
          description: A list of messages for the given thread
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: '#/components/schemas/ThreadMessage'
      security:
        - BearerAuth: []
          ProjectIdAuth: []
          
  /threads/{thread_id}/cost:
    get:
      operationId: getThreadCost
      tags:
        - Threads
      summary: Retrieve the total cost for a specific thread
      parameters:
        - name: thread_id
          in: path
          required: true
          schema:
            type: string
            format: uuid
          description: The ID of the thread for which to retrieve cost information
      responses:
        '200':
          description: The total cost and token usage for the specified thread
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ThreadCost'
      security:
        - BearerAuth: []
          ProjectIdAuth: []
          

  /analytics:
    post:
      tags:
        - Analytics
      summary: Fetch analytics data
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                start_time_us:
                  type: integer
                  format: int64
                  description: "Start time in microseconds."
                end_time_us:
                  type: integer
                  format: int64
                  description: "End time in microseconds."
              example: |
                {
                  "start_time_us": 1693062345678,
                  "end_time_us": 1693082345678
                }
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AnalyticsResponse'
      security:
        - BearerAuth: []
          ProjectIdAuth: []

  /analytics/summary:
    post:
      tags:
        - Analytics
      summary: Fetch analytics summary
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                start_time_us:
                  type: integer
                  format: int64
                end_time_us:
                  type: integer
                  format: int64
                groupBy:
                  type: array
                  items:
                    type: string
              example: |
                {
                  "start_time_us": 1693062345678,
                  "end_time_us": 1693082345678,
                  "groupBy": ["provider"]
                }
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AnalyticsSummaryResponse'
      security:
        - BearerAuth: []
          ProjectIdAuth: []

  /usage/total:
    post:
      tags:
        - Analytics
      summary: Get total usage
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                start_time_us:
                  type: integer
                  format: int64
                end_time_us:
                  type: integer
                  format: int64
              example: |
                {
                  "start_time_us": 1693062345678,
                  "end_time_us": 1693082345678
                }
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/TotalUsageResponse'
      security:
        - BearerAuth: []
          ProjectIdAuth: []

  /usage/models:
    post:
      tags:
        - Analytics
      summary: Get usage by model
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                start_time_us:
                  type: integer
                  format: int64
                end_time_us:
                  type: integer
                  format: int64
                min_unit:
                  type: string
                  enum: [hour, day, month]
                  description: "The granularity of the returned usage data."
              example: |
                {
                  "start_time_us": 1693062345678,
                  "end_time_us": 1693082345678,
                  "min_unit": "hour"
                }
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/GranularUsageResponse'
      security:
        - BearerAuth: []
          ProjectIdAuth: []
  /pricing:
    get:
      operationId: getPricing
      tags:
        - Pricing
      summary: Retrieve pricing information
      description: Returns the pricing details for LangDB services.
      responses:
        '200':
          description: Successful retrieval of pricing information
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ModelPricing'
  /models:
    get:
      operationId: listModels
      tags:
        - Models
      summary: List models
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                type: object
                properties:
                 object:
                   type: string
                   description: "Type of the response, e.g. 'list'."
                   example: list
                 data:
                   type: array
                   description: "Array of model objects."
                   items:
                     type: object
                     properties:
                       id:
                         type: string
                         description: "Unique identifier for the model."
                         example: o1-mini
                       object:
                         type: string
                         description: "Object type, typically 'model'."
                         example: model
                       created:
                         type: integer
                         description: "Unix timestamp when the model was created."
                         example: 1686935002
                       owned_by:
                         type: string
                         description: "Owner of the model."
                         example: openai
  
components:
  securitySchemes:
    BearerAuth:
      type: http
      scheme: bearer
    ProjectIdAuth:
      type: apiKey
      in: header
      name: X-Project-Id
  schemas:
    CreateChatCompletionRequest:
      type: object
      required:
        - model
        - messages
      properties:
        model:
          type: string
          description: ID of the model to use.
          example: gpt-4o
        messages:
          type: array
          description: A list of messages in the conversation.
          items:
            type: object
            properties:
              role:
                type: string
                enum:
                  - system
                  - user
                  - assistant
              content:
                type: string
          example:
            - role: system
              content: "You are a helpful assistant."
            - role: user
              content: "Write a haiku about recursion in programming."
        temperature:
          type: number
          minimum: 0
          maximum: 2
          description: Sampling temperature.
          example: 0.8
    CreateChatCompletionResponse:
      type: object
      description: Represents a chat completion response returned by model, based on the provided input.
      properties:
        id:
          type: string
          description: A unique identifier for the chat completion.
        choices:
          type: array
          description: A list of chat completion choices. Can be more than one if `n` is greater than 1.
          items:
            type: object
            required:
              - finish_reason
              - index
              - message
              - logprobs
            properties:
              finish_reason:
                type: string
                description: |
                  The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,
                  `length` if the maximum number of tokens specified in the request was reached,
                  `content_filter` if content was omitted due to a flag from our content filters,
                  `tool_calls` if the model called a tool, or `function_call` (deprecated) if the model called a function.
                enum:
                  - stop
                  - length
                  - tool_calls
                  - content_filter
                  - function_call
              index:
                type: integer
                description: The index of the choice in the list of choices.
              message:
                $ref: '#/components/schemas/ChatCompletionResponseMessage'
              logprobs:
                description: Log probability information for the choice.
                type: object
                nullable: true
                properties:
                  content:
                    description: A list of message content tokens with log probability information.
                    type: array
                    items:
                      $ref: '#/components/schemas/ChatCompletionTokenLogprob'
                    nullable: true
                  refusal:
                    description: A list of message refusal tokens with log probability information.
                    type: array
                    items:
                      $ref: '#/components/schemas/ChatCompletionTokenLogprob'
                    nullable: true
                required:
                  - content
                  - refusal
        created:
          type: integer
          description: The Unix timestamp (in seconds) of when the chat completion was created.
        model:
          type: string
          description: The model used for the chat completion.
        service_tier:
          description: The service tier used for processing the request. This field is only included if the `service_tier` parameter is specified in the request.
          type: string
          enum:
            - scale
            - default
          example: scale
          nullable: true
        system_fingerprint:
          type: string
          description: |
            This fingerprint represents the backend configuration that the model runs with.

            Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.
        object:
          type: string
          description: The object type, which is always `chat.completion`.
          enum:
            - chat.completion
        usage:
          $ref: '#/components/schemas/CompletionUsage'
      required:
        - choices
        - created
        - id
        - model
        - object
      x-oaiMeta:
        name: The chat completion object
        group: chat
        example: |
          {
            "id": "chatcmpl-123456",
            "object": "chat.completion",
            "created": 1728933352,
            "model": "gpt-4o-2024-08-06",
            "choices": [
              {
                "index": 0,
                "message": {
                  "role": "assistant",
                  "content": "Hi there! How can I assist you today?",
                  "refusal": null
                },
                "logprobs": null,
                "finish_reason": "stop"
              }
            ],
            "usage": {
              "prompt_tokens": 19,
              "completion_tokens": 10,
              "total_tokens": 29,
              "prompt_tokens_details": {
                "cached_tokens": 0
              },
              "completion_tokens_details": {
                "reasoning_tokens": 0,
                "accepted_prediction_tokens": 0,
                "rejected_prediction_tokens": 0
              }
            },
            "system_fingerprint": "fp_6b68a8204b"
          }
    ExecuteRequest:
      type: object
      properties:
        query:
          type: string
          description: The query to be executed.
          example: SELECT * FROM langdb.models;
        params:
          description: Parameters required for the action
          oneOf:
            - type: object
              description: An empty object
              properties: {}
              additionalProperties: false
            - type: object
              description: An object with string properties
              additionalProperties:
                type: string
      required:
        - query
    ExecuteResponse:
      type: object
      description: Result of the executed action
      properties:
        data:
          type: object
          description: The result data returned by the action
        message:
          type: string
          description: Optional message or status information
      additionalProperties: true

    FetchResourceRequest:
      type: object
      description: Parameters required to fetch the resource
      additionalProperties:
        type: string
    FetchResourceResponse:
      type: object
      description: Result of the resource execution
      additionalProperties: true
    ErrorResponse:
      type: object
      properties:
        error:
          type: string
          description: Error message describing what went wrong.
        code:
          type: string
          description: Error code representing the type of error.
      required:
        - error
        - code
    FetchMappedDataRequest:
      type: object
      properties:
        virtual_table_name:
          type: string
          description: Name of the virtual table to fetch data from
        params:
          type: object
          additionalProperties:
            type: string
          description: Parameters required to fetch the mapped data
      required:
        - virtual_table_name
        - params
    DataIntegration:
      type: object
      properties:
        id:
          type: string
          description: Unique identifier for the integration.
        integration_name:
          type: string
          description: Name of the integration.
        state:
          type: string
          description: Current state of the integration (e.g., enabled, disabled).
          enum:
            - enabled
            - disabled
        created_at:
          type: string
          format: date-time
          description: Timestamp when the integration was created.
        config:
          type: object
          description: Configuration details for the integration.
          additionalProperties: true
      required:
        - id
        - integration_name
        - config
        - state
        - created_at
    Integration:
      type: object
      properties:
        name:
          type: string
          description: Name of the integration.
        auth_type:
          type: string
          description: Type of authentication required by the integration.
          enum:
            - oauth
            - native
        required_inputs:
          type: array
          items:
            type: string
          description: List of required input fields for the integration.
      required:
        - name
        - auth_type
        - required_inputs
    IntegrationAction:
      type: object
      properties:
        name:
          type: string
          description: Unique identifier for the action.
        description:
          type: string
          description: Human-readable description of the action.
        input_schema:
          type: string
          description: JSON Schema for validating inputs.
          nullable: true
        output_schema:
          type: string
          description: JSON Schema for validating outputs.
          nullable: true
      required:
        - name
        - description
    ChatCompletionRequest:
      type: object
      properties:
        model:
          type: string
          description: The model to use for generating the completion.
        messages:
          type: array
          items:
            $ref: '#/components/schemas/ChatCompletionMessage'
          description: The messages to include in the conversation.
        temperature:
          type: number
          description: Sampling temperature between 0 and 2.
          default: 1
        top_p:
          type: number
          description: Nucleus sampling probability between 0 and 1.
          default: 1
        max_tokens:
          type: integer
          description: Maximum number of tokens to generate.
        presence_penalty:
          type: number
          description: Penalty for new tokens based on their presence in the text so far.
          default: 0
        frequency_penalty:
          type: number
          description: Penalty for new tokens based on their frequency in the text so far.
          default: 0
        user:
          type: string
          description: Unique identifier representing your end-user.
        functions:
          type: array
          items:
            $ref: '#/components/schemas/FunctionDefinition'
          description: List of functions the model may generate JSON inputs for.
        seed:
          type: integer
          description: Seed for random number generation.
      required:
        - model
        - messages
    ChatCompletionMessage:
      type: object
      properties:
        role:
          type: string
          description: The role of the message sender.
          enum:
            - system
            - user
            - assistant
        content:
          type: string
          description: The content of the message.
        name:
          type: string
          description: Optional name of the user in a multi-user chat.
        function_call:
          type: object
          description: Function call details if the assistant called a function.
      required:
        - role
        - content
    FunctionDefinition:
      type: object
      properties:
        name:
          type: string
          description: The name of the function.
        description:
          type: string
          description: A description of what the function does.
        parameters:
          type: object
          description: JSON Schema defining the parameters the function accepts.
      required:
        - name
        - description
    ChatCompletionResponse:
      type: object
      properties:
        id:
          type: string
          description: Unique identifier for the completion.
        object:
          type: string
          description: The object type, e.g., 'chat.completion'.
        created:
          type: integer
          description: Timestamp of completion creation.
        model:
          type: string
          description: The model used for the completion.
        choices:
          type: array
          items:
            $ref: '#/components/schemas/ChatCompletionChoice'
          description: List of completion choices.
        usage:
          $ref: '#/components/schemas/ChatCompletionUsage'
          description: Token usage statistics.
      required:
        - id
        - object
        - created
        - model
        - choices
        - usage
    ChatCompletionChoice:
      type: object
      properties:
        index:
          type: integer
          description: The choice index.
        message:
          $ref: '#/components/schemas/ChatCompletionMessage'
          description: The message returned by the model.
        finish_reason:
          type: string
          description: The reason why the completion finished.
      required:
        - index
        - message
    ChatCompletionUsage:
      type: object
      properties:
        prompt_tokens:
          type: integer
          description: Number of tokens in the prompt.
        completion_tokens:
          type: integer
          description: Number of tokens in the completion.
        total_tokens:
          type: integer
          description: Total number of tokens used.
      required:
        - prompt_tokens
        - completion_tokens
        - total_tokens
    ResponseFormatJsonObject:
      type: object
      properties:
        type:
          type: string
          description: 'The type of response format being defined: `json_object`'
          enum:
            - json_object
      required:
        - type
    ResponseFormatJsonSchema:
      type: object
      properties:
        type:
          type: string
          description: 'The type of response format being defined: `json_schema`'
          enum:
            - json_schema
        json_schema:
          type: object
          properties:
            description:
              type: string
              description: A description of what the response format is for, used by the model to determine how to respond in the format.
            name:
              type: string
              description: The name of the response format. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.
            schema:
              $ref: '#/components/schemas/ResponseFormatJsonSchemaSchema'
            strict:
              type: boolean
              nullable: true
              default: false
              description: Whether to enable strict schema adherence when generating the output. If set to true, the model will always follow the exact schema defined in the `schema` field. Only a subset of JSON Schema is supported when `strict` is `true`. To learn more, read the [Structured Outputs guide](/docs/guides/structured-outputs).
          required:
            - type
            - name
      required:
        - type
        - json_schema
    ResponseFormatJsonSchemaSchema:
      type: object
      description: The schema for the response format, described as a JSON Schema object.
      additionalProperties: true
    ResponseFormatText:
      type: object
      properties:
        type:
          type: string
          description: 'The type of response format being defined: `text`'
          enum:
            - text
      required:
        - type
    QueryResult:
      type: object
      description: Result of the executed query.
      additionalProperties: true
    ChatCompletionFunctionCallOption:
      type: object
      properties:
        name:
          type: string
          description: The name of the function to call.
        arguments:
          type: string
          description: The arguments to call the function with, as generated by the model in JSON format.
      required:
        - name
        - arguments
    ChatCompletionFunctions:
      type: object
      properties:
        name:
          type: string
          description: The name of the function to call.
        description:
          type: string
          description: A description of what the function does, used by the model to choose when and how to call the function.
        parameters:
          type: object
          description: The parameters the functions accepts, described as a JSON Schema object.
      required:
        - name
        - parameters
    ChatCompletionMessageToolCall:
      type: object
      properties:
        id:
          type: string
        type:
          type: string
          enum:
            - function
        function:
          type: object
          properties:
            name:
              type: string
              description: The name of the function to call.
            arguments:
              type: string
              description: The arguments to call the function with, as generated by the model in JSON format.
            output:
              type: string
              nullable: true
              description: The output of the function call, as provided in the run step.
          required:
            - name
            - arguments
      required:
        - id
        - type
        - function
    ChatCompletionMessageToolCalls:
      type: array
      items:
        $ref: '#/components/schemas/ChatCompletionMessageToolCall'
    ChatCompletionModalities:
      type: array
      description: A list of modalities to include in the response.
      items:
        type: string
        enum:
          - text
          - audio
          - image
          - vision
      minItems: 1
    ChatCompletionNamedToolChoice:
      type: object
      properties:
        type:
          type: string
          enum:
            - function
        function:
          type: object
          properties:
            name:
              type: string
              description: The name of the function to call.
          required:
            - name
      required:
        - type
        - function
    ChatCompletionRequestAssistantMessage:
      type: object
      title: Assistant message
      properties:
        content:
          oneOf:
            - type: string
              nullable: true
            - type: array
              items:
                $ref: '#/components/schemas/ChatCompletionRequestAssistantMessageContentPart'
        role:
          type: string
          enum:
            - assistant
        tool_calls:
          $ref: '#/components/schemas/ChatCompletionMessageToolCalls'
        name:
          type: string
          description: An optional name for the participant. Provides the model information about who is speaking.
      required:
        - role
    ChatCompletionRequestAssistantMessageContentPart:
      oneOf:
        - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartText'
        - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartRefusal'
    ChatCompletionRequestFunctionMessage:
      type: object
      title: Function message
      properties:
        content:
          type: string
          description: The contents of the function message.
        role:
          type: string
          enum:
            - function
        name:
          type: string
          description: The name of the function to call.
      required:
        - content
        - role
        - name
    ChatCompletionRequestMessage:
      oneOf:
        - $ref: '#/components/schemas/ChatCompletionRequestSystemMessage'
        - $ref: '#/components/schemas/ChatCompletionRequestUserMessage'
        - $ref: '#/components/schemas/ChatCompletionRequestAssistantMessage'
        - $ref: '#/components/schemas/ChatCompletionRequestToolMessage'
        - $ref: '#/components/schemas/ChatCompletionRequestFunctionMessage'
    ChatCompletionRequestMessageContentPartAudio:
      type: object
      title: Audio content part
      properties:
        type:
          type: string
          enum:
            - audio_url
        audio_url:
          type: object
          properties:
            url:
              type: string
              format: uri
              pattern: ^https?://
              description: The URL of the audio file.
          required:
            - url
      required:
        - type
        - audio_url
    ChatCompletionRequestMessageContentPartImage:
      type: object
      title: Image content part
      properties:
        type:
          type: string
          enum:
            - image_url
        image_url:
          type: object
          properties:
            url:
              type: string
              format: uri
              pattern: ^https?://
              description: Either a URL of the image or the base64 encoded image data.
            detail:
              type: string
              enum:
                - auto
                - low
                - high
              default: auto
              description: Controls how the model processes the image and the detail of analysis it performs.
          required:
            - url
      required:
        - type
        - image_url
    ChatCompletionRequestMessageContentPartText:
      type: object
      title: Text content part
      description: |
        Learn about [text inputs](/docs/guides/text-generation).
      properties:
        type:
          type: string
          enum:
            - text
          description: The type of the content part.
        text:
          type: string
          description: The text content.
      required:
        - type
        - text
    ChatCompletionRequestMessageContentPartRefusal:
      type: object
      title: Refusal content part
      properties:
        type:
          type: string
          enum:
            - refusal
        refusal:
          type: object
          properties:
            category:
              type: string
              enum:
                - content_policy
                - privacy_policy
                - other
              description: The category of refusal.
            explanation:
              type: string
              description: A human-readable explanation of the refusal.
          required:
            - category
            - explanation
      required:
        - type
        - refusal
    ChatCompletionRequestSystemMessage:
      type: object
      title: System message
      properties:
        content:
          description: The contents of the system message.
          oneOf:
            - type: string
              description: The contents of the system message.
              title: Text content
            - type: array
              description: An array of content parts with a defined type. For system messages, only type `text` is supported.
              title: Array of content parts
              items:
                $ref: '#/components/schemas/ChatCompletionRequestSystemMessageContentPart'
              minItems: 1
        role:
          type: string
          enum:
            - system
          description: The role of the messages author, in this case `system`.
        name:
          type: string
          description: An optional name for the participant. Provides the model information to differentiate between participants of the same role.
      required:
        - content
        - role
    ChatCompletionRequestToolMessage:
      type: object
      title: Tool message
      properties:
        role:
          type: string
          enum:
            - tool
          description: The role of the messages author, in this case `tool`.
        content:
          oneOf:
            - type: string
              description: The contents of the tool message.
              title: Text content
            - type: array
              description: An array of content parts with a defined type. For tool messages, only type `text` is supported.
              title: Array of content parts
              items:
                $ref: '#/components/schemas/ChatCompletionRequestToolMessageContentPart'
              minItems: 1
          description: The contents of the tool message.
        tool_call_id:
          type: string
          description: Tool call that this message is responding to.
      required:
        - role
        - content
        - tool_call_id
    ChatCompletionRequestUserMessage:
      type: object
      title: User message
      properties:
        content:
          oneOf:
            - type: string
            - type: array
              items:
                oneOf:
                  - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartText'
                  - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartImage'
                  - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartAudio'
                x-oaiExpandable: true
        role:
          type: string
          enum:
            - user
        name:
          type: string
          description: An optional name for the participant. Provides the model information about who is speaking.
      required:
        - content
        - role
    ChatCompletionResponseMessage:
      type: object
      properties:
        role:
          type: string
          enum:
            - assistant
            - tool
        content:
          type: string
          nullable: true
        tool_calls:
          type: array
          items:
            $ref: '#/components/schemas/ChatCompletionMessageToolCall'
        function_call:
          $ref: '#/components/schemas/ChatCompletionFunctionCallOption'
      required:
        - role
    ChatCompletionStreamOptions:
      description: 'Options for streaming response. Only set this when you set `stream: true`'
      type: object
      properties:
        chunk_size:
          type: integer
          minimum: 1
          maximum: 4096
          default: 1024
          description: The number of tokens to generate before sending a chunk to the client.
        max_chunks:
          type: integer
          minimum: 1
          maximum: 100
          default: 10
          description: The maximum number of chunks to generate.
        stop_on_function_call:
          type: boolean
          default: false
          description: If true, stop generating when a function call is generated.
    ChatCompletionTool:
      type: object
      properties:
        type:
          type: string
          enum:
            - function
          description: The type of the tool. Currently, only `function` is supported.
        function:
          $ref: '#/components/schemas/FunctionObject'
      required:
        - type
        - function
    ChatCompletionToolChoiceOption:
      description: |
        Controls which (if any) tool is called by the model. `none` means the model will not call any tool and instead generates a message. `auto` means the model can pick between generating a message or calling one or more tools. `required` means the model must call one or more tools. Specifying a particular tool via `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool. `none` is the default when no tools are present. `auto` is the default if tools are present.
      oneOf:
        - type: string
          description: |
            `none` means the model will not call any tool and instead generates a message. `auto` means the model can pick between generating a message or calling one or more tools. `required` means the model must call one or more tools.
          enum:
            - none
            - auto
            - required
        - $ref: '#/components/schemas/ChatCompletionNamedToolChoice'
      x-oaiExpandable: true
    ChatCompletionRequestSystemMessageContentPart:
      oneOf:
        - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartText'
      x-oaiExpandable: true
    ChatCompletionRequestToolMessageContentPart:
      oneOf:
        - $ref: '#/components/schemas/ChatCompletionRequestMessageContentPartText'
      x-oaiExpandable: true
    ParallelToolCalls:
      type: integer
      description: |
        The maximum number of tool calls that can be made in parallel. If not set, defaults to 1. Set this to a number greater than 1 to enable parallel tool calls.
      minimum: 1
      default: 1
    ChatCompletionTokenLogprob:
      type: object
      properties:
        token:
          type: string
          description: The token.
        logprob:
          type: number
          description: The log probability of the token.
        bytes:
          type: array
          items:
            type: integer
          description: The UTF-8 bytes of the token.
        top_logprobs:
          type: array
          items:
            type: object
            properties:
              token:
                type: string
                description: A potential token.
              logprob:
                type: number
                description: The log probability of the token.
              bytes:
                type: array
                items:
                  type: integer
                description: The UTF-8 bytes of the token.
            required:
              - token
              - logprob
          description: Top tokens and their log probabilities.
      required:
        - token
        - logprob
        - bytes
    FunctionObject:
      type: object
      properties:
        description:
          type: string
          description: A description of what the function does, used by the model to choose when and how to call the function.
        name:
          type: string
          description: The name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and dashes, with a maximum length of 64.
        parameters:
          $ref: '#/components/schemas/FunctionParameters'
        strict:
          type: boolean
          nullable: true
          default: false
          description: Whether to enable strict schema adherence when generating the function call. If set to true, the model will follow the exact schema defined in the `parameters` field. Only a subset of JSON Schema is supported when `strict` is `true`. Learn more about Structured Outputs in the [function calling guide](docs/guides/function-calling).
      required:
        - name
    FunctionParameters:
      type: object
      description: |-
        The parameters the functions accepts, described as a JSON Schema object. See the [guide](/docs/guides/function-calling) for examples, and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation about the format. 

        Omitting `parameters` defines a function with an empty parameter list.
      additionalProperties: true
    Image:
      type: object
      description: Represents the url or the content of an image generated by the API.
      properties:
        b64_json:
          type: string
          description: The base64-encoded JSON of the generated image, if `response_format` is `b64_json`.
        url:
          type: string
          description: The URL of the generated image, if `response_format` is `url` (default).
        revised_prompt:
          type: string
          description: The prompt that was used to generate the image, if there was any revision to the prompt.
      x-oaiMeta:
        name: The image object
        example: |
          {
            "url": "...",
            "revised_prompt": "..."
          }
    CompletionUsage:
      type: object
      description: Usage statistics for the completion request.
      properties:
        completion_tokens:
          type: integer
          description: Number of tokens in the generated completion.
        prompt_tokens:
          type: integer
          description: Number of tokens in the prompt.
        total_tokens:
          type: integer
          description: Total number of tokens used in the request (prompt + completion).
        completion_tokens_details:
          type: object
          description: Breakdown of tokens used in a completion.
          properties:
            accepted_prediction_tokens:
              type: integer
              description: |
                When using Predicted Outputs, the number of tokens in the
                prediction that appeared in the completion.
            audio_tokens:
              type: integer
              description: Audio input tokens generated by the model.
            reasoning_tokens:
              type: integer
              description: Tokens generated by the model for reasoning.
            rejected_prediction_tokens:
              type: integer
              description: |
                When using Predicted Outputs, the number of tokens in the
                prediction that did not appear in the completion. However, like
                reasoning tokens, these tokens are still counted in the total
                completion tokens for purposes of billing, output, and context window
                limits.
        prompt_tokens_details:
          type: object
          description: Breakdown of tokens used in the prompt.
          properties:
            audio_tokens:
              type: integer
              description: Audio input tokens present in the prompt.
            cached_tokens:
              type: integer
              description: Cached tokens present in the prompt.
      required:
        - prompt_tokens
        - completion_tokens
        - total_tokens
    ListModelsResponse:
      type: object
      properties:
        object:
          type: string
          enum:
            - list
        data:
          type: array
          items:
            $ref: '#/components/schemas/Model'
      required:
        - object
        - data
    Model:
      title: Model
      description: Describes an LLM model offering that can be used with the API.
      properties:
        id:
          type: string
          description: The model identifier, which can be referenced in the API endpoints.
        created:
          type: integer
          description: The Unix timestamp (in seconds) when the model was created.
        object:
          type: string
          description: The object type, which is always "model".
          enum:
            - model
        owned_by:
          type: string
          description: The organization that owns the model.
      required:
        - id
        - object
        - created
        - owned_by
      x-oaiMeta:
        name: The model object
        example: |
          {
            "id": "VAR_model_id",
            "object": "model",
            "created": 1686935002,
            "owned_by": "openai"
          }
    TraceResponse:
      type: object
      description: Represents one span within a trace
      properties:
        trace_id:
          type: string
          description: The unique trace ID (UUID).
        span_id:
          type: integer
          description: The unique span ID.
        parent_span_id:
          type: integer
          description: The span ID of the parent span.
        operation_name:
          type: string
          description: The name of the operation (e.g., 'model_call', 'api_invoke').
        kind:
          type: string
          description: The kind of this span (e.g., 'INTERNAL').
        start_time_us:
          type: integer
          description: Start time in microseconds.
        finish_time_us:
          type: integer
          description: Finish time in microseconds.
        attribute:
          type: object
          description: Key-value data or metadata about this span.
          additionalProperties: true  # if you want arbitrary key-value pairs
      required:
        - trace_id
        - span_id
        - parent_span_id
        - operation_name
        - kind
        - start_time_us
        - finish_time_us
        - attribute
    ModelPricing:
      type: object
      properties:
        model:
          type: string
          example: gpt-3.5-turbo-0125
        provider:
          type: string
          example: openai
        price:
          $ref: '#/components/schemas/PriceDetails'
        input_formats:
          type: array
          items:
            type: string
          example: ["text"]
        output_formats:
          type: array
          items:
            type: string
          example: ["text"]
        capabilities:
          type: array
          items:
            type: string
          example: ["tools"]
        type:
          type: string
          example: completions
        limits:
          $ref: '#/components/schemas/UsageLimits'

    PriceDetails:
      type: object
      properties:
        per_input_token:
          type: number
          format: float
          example: 0.5
        per_output_token:
          type: number
          format: float
          example: 1.5
        valid_from:
          type: string
          format: date-time
          nullable: true
          example: null

    UsageLimits:
      type: object
      properties:
        max_context_size:
          type: integer
          example: 16385
    EmbeddingsRequest:
      type: object
      description: The request body for generating embeddings.
      required:
        - input
        - model
      properties:
        input:
          description: |
            The text to embed, or an array of text strings/tokens.
            Can be:
              - A single string  
              - An array of strings  
              - An array of token arrays (advanced use)
          oneOf:
            - type: string
            - type: array
              items:
                oneOf:
                  - type: string
                  - type: array
                    items:
                      type: integer
        model:
          type: string
          description: |
            ID of the embeddings model to use (e.g. `text-embedding-ada-002`).
        encoding_format:
          type: string
          enum: [float, base64]
          default: float
          description: |
            Format to return the embeddings in:
              - `float` -> array of floats
              - `base64` -> base64-encoded data
        dimensions:
          type: integer
          description: |
            The number of dimensions for the returned embeddings (if supported by the model).
            e.g. `1536` for `text-embedding-ada-002`
        user:
          type: string
          description: |
            A unique identifier for your end-user, useful for logging or analytics.
      example:
        input: "The food was delicious and the waiter was kind."
        model: "text-embedding-ada-002"
        encoding_format: "float"
        dimensions: 1536
        user: "user-1234"

    EmbeddingsResponse:
      type: object
      description: The response containing one or more embeddings.
      properties:
        object:
          type: string
          enum: [list]
          description: Typically "list".
          example: "list"
        data:
          type: array
          description: An array of embedding objects (one per input).
          items:
            type: object
            properties:
              object:
                type: string
                enum: [embedding]
                description: Typically "embedding".
                example: "embedding"
              embedding:
                type: array
                description: The embedding vector.
                items:
                  type: number
                example:
                  - 0.0023064255
                  - -0.009327292
                  - -0.0028842222
              index:
                type: integer
                description: The index of the input in the request.
        model:
          type: string
          description: The model used to generate embeddings.
        usage:
          type: object
          description: Optional usage data for token billing.
          properties:
            prompt_tokens:
              type: integer
              description: Number of tokens in the prompt.
            total_tokens:
              type: integer
              description: Total tokens consumed (prompt + overhead).
      example:
        object: "list"
        data:
          - object: "embedding"
            embedding: [0.0023064255, -0.009327292, -0.0028842222]
            index: 0
        model: "text-embedding-ada-002"
        usage:
          prompt_tokens: 8
          total_tokens: 8
    ThreadsRequest:
      type: object
      properties:
        limit:
          type: integer
          minimum: 1
          example: 10
        offset:
          type: integer
          minimum: 0
          example: 100
      required:
        - limit
        - offset

    ModelUsage:
      type: object
      required:
        - provider
        - model_name
        - total_input_tokens
        - total_output_tokens
        - total_cost
        - cost_per_input_token
        - cost_per_output_token
      properties:
        provider:
          type: string
          description: The provider of the model (e.g. openai, gemini, etc)
        model_name:
          type: string
          description: The name of the model
        total_input_tokens:
          type: integer
          description: Total number of input tokens used
        total_output_tokens:
          type: integer
          description: Total number of output tokens generated
        total_cost:
          type: number
          format: double
          description: Total cost in USD
        cost_per_input_token:
          type: number
          format: double
          description: Cost per input token in USD
        cost_per_output_token:
          type: number
          format: double
          description: Cost per output token in USD

    TotalUsageSummary:
      type: object
      required:
        - total_input_tokens
        - total_output_tokens
        - total_cost
      properties:
        total_input_tokens:
          type: integer
          description: Total input tokens across all models
        total_output_tokens:
          type: integer
          description: Total output tokens across all models
        total_cost:
          type: number
          format: double
          description: Total cost across all models in USD

    TotalUsageResponse:
      type: object
      required:
        - models
        - total
        - period_start
        - period_end
      properties:
        models:
          type: array
          items:
            $ref: '#/components/schemas/ModelUsage'
          description: Usage statistics for each model
        total:
          $ref: '#/components/schemas/TotalUsageSummary'
          description: Aggregated usage statistics across all models
        period_start:
          type: integer
          format: int64
          description: Start of the usage period in microseconds since epoch
        period_end:
          type: integer
          format: int64
          description: End of the usage period in microseconds since epoch

    GranularModelUsage:
      type: object
      required:
        - time
        - provider
        - model_name
        - total_input_tokens
        - total_output_tokens
        - total_cost
      properties:
        time:
          type: string
          description: >
            The timestamp corresponding to the usage data. The format depends on the requested granularity:
            - Hourly: "YYYY-MM-DD HH:mm:ss"
            - Daily: "YYYY-MM-DD"
            - Monthly: "YYYY-MM"
        provider:
          type: string
          description: "The provider of the model (e.g. openai, gemini, etc.)"
        model_name:
          type: string
          description: "The name of the model"
        total_input_tokens:
          type: integer
          description: "Total number of input tokens used"
        total_output_tokens:
          type: integer
          description: "Total number of output tokens generated"
        total_cost:
          type: number
          format: double
          description: "Total cost in USD"


    GranularUsageResponse:
      type: object
      required:
        - models
        - period_start
        - period_end
      properties:
        models:
          type: array
          description: "Usage statistics for each model at the specified granularity (hourly, daily, or monthly)"
          items:
            $ref: '#/components/schemas/GranularModelUsage'
        period_start:
          type: integer
          format: int64
          description: "Start of the usage period in microseconds since epoch"
        period_end:
          type: integer
          format: int64
          description: "End of the usage period in microseconds since epoch"

    ThreadsResponse:
      type: object
      properties:
        data:
          type: array
          description: An array of thread objects
          items:
            $ref: '#/components/schemas/Thread'
        pagination:
          $ref: '#/components/schemas/ThreadsPagination'
      required:
        - data
        - pagination

    Thread:
      type: object
      properties:
        id:
          type: string
          format: uuid
        created_at:
          type: string
          format: date-time
        updated_at:
          type: string
          format: date-time
        model_name:
          type: string
        project_id:
          type: string
        score:
          type: number
          nullable: true
        title:
          type: string
        user_id:
          type: string
      required:
        - id
        - created_at
        - updated_at
        - model_name
        - project_id
        - user_id

    ThreadsPagination:
      type: object
      properties:
        limit:
          type: integer
          example: 10
        offset:
          type: integer
          example: 100
        total:
          type: integer
          example: 10
      required:
        - limit
        - offset
        - total
    ThreadMessage:
      type: object
      properties:
        model_name:
          type: string
          example: gpt-4o-mini
        thread_id:
          type: string
          format: uuid
        user_id:
          type: string
          example: langdb
        content_type:
          type: string
          example: Text
        content:
          type: string
          description: The raw text or structured content of the message
        content_array:
          type: array
          description: In some cases, message content may be split into multiple parts
          items:
            type: string
        type:
          type: string
          description: The role or type of message (e.g., system, human, ai)
          example: system
        tool_call_id:
          type: string
          format: uuid
          nullable: true
          description: If relevant, the ID of the tool call
        tool_calls:
          type: string
          nullable: true
          description: Any tool calls (if applicable) related to this message
        created_at:
          type: string
          format: date-time
          example: "2025-01-29 10:25:00.736000"
        id:
          type: string
          format: uuid
          description: The unique identifier for the message
      required:
        - model_name
        - thread_id
        - user_id
        - content_type
        - content
        - type
        - created_at
        - id
    ThreadCost:
      type: object
      properties:
        total_cost:
          type: number
          format: float
          description: The total cost of the thread
          example: 0.022226999999999997
        total_output_tokens:
          type: integer
          description: The number of output tokens used
          example: 171
        total_input_tokens:
          type: integer
          description: The number of input tokens used
          example: 6725
      required:
        - total_cost
        - total_output_tokens
        - total_input_tokens
    AnalyticsResponse:
      type: object
      required:
        - timeseries
        - start_time_us
        - end_time_us
      properties:
        timeseries:
          type: array
          description: "An array of analytics timeseries records."
          items:
            type: object
            required:
              - hour
              - total_cost
              - total_requests
              - avg_duration
              - duration
              - duration_p99
              - duration_p95
              - duration_p90
              - duration_p50
              - total_duration
              - total_input_tokens
              - total_output_tokens
              - error_rate
              - error_request_count
              - avg_ttft
              - ttft
              - ttft_p99
              - ttft_p95
              - ttft_p90
              - ttft_p50
              - tps
              - tps_p99
              - tps_p95
              - tps_p90
              - tps_p50
              - tpot
              - tpot_p99
              - tpot_p95
              - tpot_p90
              - tpot_p50
              - tag_tuple
            properties:
              hour:
                type: string
                description: "The timestamp for the record (e.g. 'YYYY-MM-DD HH:mm:ss')."
              total_cost:
                type: number
                format: double
                description: "Total cost incurred during this period."
              total_requests:
                type: integer
                description: "Total number of requests."
              avg_duration:
                type: number
                format: double
                description: "Average duration (in milliseconds) of requests."
              duration:
                type: number
                format: double
                description: "Duration (in milliseconds) of requests."
              duration_p99:
                type: number
                format: double
                description: "99th percentile of request durations."
              duration_p95:
                type: number
                format: double
                description: "95th percentile of request durations."
              duration_p90:
                type: number
                format: double
                description: "90th percentile of request durations."
              duration_p50:
                type: number
                format: double
                description: "50th percentile of request durations."
              total_duration:
                type: number
                format: double
                description: "Total duration (in milliseconds) of all requests."
              total_input_tokens:
                type: integer
                description: "Total number of input tokens used."
              total_output_tokens:
                type: integer
                description: "Total number of output tokens generated."
              error_rate:
                type: number
                format: double
                description: "Error rate (as a percentage) over the period."
              error_request_count:
                type: integer
                description: "Number of error requests."
              avg_ttft:
                type: number
                format: double
                description: "Average time to first byte (TTFT) in milliseconds."
              ttft:
                type: number
                format: double
                description: "Time to first byte (TTFT) in milliseconds."
              ttft_p99:
                type: number
                format: double
                description: "99th percentile of TTFT."
              ttft_p95:
                type: number
                format: double
                description: "95th percentile of TTFT."
              ttft_p90:
                type: number
                format: double
                description: "90th percentile of TTFT."
              ttft_p50:
                type: number
                format: double
                description: "50th percentile of TTFT."
              tps:
                type: number
                format: double
                description: "Transactions per second."
              tps_p99:
                type: number
                format: double
                description: "99th percentile TPS."
              tps_p95:
                type: number
                format: double
                description: "95th percentile TPS."
              tps_p90:
                type: number
                format: double
                description: "90th percentile TPS."
              tps_p50:
                type: number
                format: double
                description: "50th percentile TPS."
              tpot:
                type: number
                format: double
                description: "Average transactions per output token (Tpot)."
              tpot_p99:
                type: number
                format: double
                description: "99th percentile of Tpot."
              tpot_p95:
                type: number
                format: double
                description: "95th percentile of Tpot."
              tpot_p90:
                type: number
                format: double
                description: "90th percentile of Tpot."
              tpot_p50:
                type: number
                format: double
                description: "50th percentile of Tpot."
              tag_tuple:
                type: array
                items:
                  type: string
                description: "A tuple of tags associated with the record."
        start_time_us:
          type: integer
          format: int64
          description: "Start time in microseconds since epoch."
        end_time_us:
          type: integer
          format: int64
          description: "End time in microseconds since epoch."

    AnalyticsSummaryItem:
      type: object
      required:
        - tag_tuple
        - total_cost
        - total_requests
        - total_duration
        - avg_duration
        - duration
        - duration_p99
        - duration_p95
        - duration_p90
        - duration_p50
        - total_input_tokens
        - total_output_tokens
        - avg_ttft
        - ttft
        - ttft_p99
        - ttft_p95
        - ttft_p90
        - ttft_p50
        - tps
        - tps_p99
        - tps_p95
        - tps_p90
        - tps_p50
        - tpot
        - tpot_p99
        - tpot_p95
        - tpot_p90
        - tpot_p50
        - error_rate
        - error_request_count
      properties:
        tag_tuple:
          type: array
          items:
            type: string
          description: >
            The grouping key(s) used for this summary. In this example the key is returned as tag_tuple.
            (Depending on the groupBy parameter, this field might contain provider names or model names.)
        total_cost:
          type: number
          format: double
          description: "Aggregated total cost in USD for the group."
        total_requests:
          type: integer
          description: "Aggregated total number of requests for the group."
        total_duration:
          type: number
          format: double
          description: "Aggregated total duration (in milliseconds) for the group."
        avg_duration:
          type: number
          format: double
          description: "Average duration (in milliseconds) of requests for the group."
        duration:
          type: number
          format: double
          description: "Representative duration (in milliseconds) for the group."
        duration_p99:
          type: number
          format: double
          description: "99th percentile of request durations."
        duration_p95:
          type: number
          format: double
          description: "95th percentile of request durations."
        duration_p90:
          type: number
          format: double
          description: "90th percentile of request durations."
        duration_p50:
          type: number
          format: double
          description: "50th percentile of request durations."
        total_input_tokens:
          type: integer
          description: "Aggregated total input tokens used in the group."
        total_output_tokens:
          type: integer
          description: "Aggregated total output tokens generated in the group."
        avg_ttft:
          type: number
          format: double
          description: "Average time-to-first-byte (TTFT) in milliseconds for the group."
        ttft:
          type: number
          format: double
          description: "Representative TTFT value in milliseconds for the group."
        ttft_p99:
          type: number
          format: double
          description: "99th percentile of TTFT."
        ttft_p95:
          type: number
          format: double
          description: "95th percentile of TTFT."
        ttft_p90:
          type: number
          format: double
          description: "90th percentile of TTFT."
        ttft_p50:
          type: number
          format: double
          description: "50th percentile of TTFT."
        tps:
          type: number
          format: double
          description: "Aggregated transactions per second (TPS) for the group."
        tps_p99:
          type: number
          format: double
          description: "99th percentile of TPS."
        tps_p95:
          type: number
          format: double
          description: "95th percentile of TPS."
        tps_p90:
          type: number
          format: double
          description: "90th percentile of TPS."
        tps_p50:
          type: number
          format: double
          description: "50th percentile of TPS."
        tpot:
          type: number
          format: double
          description: "Aggregated average transactions per output token (TPOT) for the group."
        tpot_p99:
          type: number
          format: double
          description: "99th percentile of TPOT."
        tpot_p95:
          type: number
          format: double
          description: "95th percentile of TPOT."
        tpot_p90:
          type: number
          format: double
          description: "90th percentile of TPOT."
        tpot_p50:
          type: number
          format: double
          description: "50th percentile of TPOT."
        error_rate:
          type: number
          format: double
          description: "Error rate (as a percentage) for the group."
        error_request_count:
          type: integer
          description: "Total number of error requests in the group."

    AnalyticsSummaryResponse:
      type: object
      required:
        - summary
        - start_time_us
        - end_time_us
      properties:
        summary:
          type: array
          description: "An array of aggregated analytics summary records."
          items:
            $ref: '#/components/schemas/AnalyticsSummaryItem'
        start_time_us:
          type: integer
          format: int64
          description: "Start time in microseconds since epoch."
        end_time_us:
          type: integer
          format: int64
          description: "End time in microseconds since epoch."
tags:
  - name: Chat
    description: API for chat completions
